{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import app\n",
    "import config\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal:\n",
    "\n",
    "My aim with this notebook is to visit the [\"Most Popular\" books](https://www.gutenberg.org/ebooks/search/?sort_order=downloads) on Project Gutenberg. I will tab to the next page, and ultimately retrieve the top 250 books on Project Gutenberg.\n",
    "\n",
    "I will first need to retrieve each book's unique identifier (e.g. Frankenstein's is 84). Then, I will use those identifiers to \"build\" URLs for each book, corresponding to their full text, as a plain text file. \n",
    "\n",
    "I will then use my punctuation tracker application to count the number of words in each book, and count their punctuations. I will add each of these data points to its own column and then save everything as a final DataFrame that can then be plotted and explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = 'biology'\n",
    "dates = pd.date_range('1922-04-21', '2022-04-21', freq='MS').strftime(\"%Y%m%d\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(dates):\n",
    "    '''Sends a request to the NYT Archive API for given date.'''\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + dates[0] + '/' + dates[1] + '.json?api-key=' + config.api_key\n",
    "    response = requests.get(url).json()\n",
    "    time.sleep(6)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(article):\n",
    "    '''An article is only worth checking if it is in range, and has a headline.'''\n",
    "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
    "    return has_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response):\n",
    "    '''Parses and returns response as pandas data frame.'''\n",
    "    data = {'headline': [],  \n",
    "        'date': [], \n",
    "        'doc_type': [],\n",
    "        'material_type': [],\n",
    "        'section': [],\n",
    "        'keywords': []}\n",
    "    \n",
    "    articles = response['response']['docs'] \n",
    "    for article in articles: # For each article, make sure it falls within our date range\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        if is_valid(article, date):\n",
    "            data['date'].append(date)\n",
    "            data['headline'].append(article['headline']['main']) \n",
    "            if 'section' in article:\n",
    "                data['section'].append(article['section_name'])\n",
    "            else:\n",
    "                data['section'].append(None)\n",
    "            data['doc_type'].append(article['document_type'])\n",
    "            if 'type_of_material' in article: \n",
    "                data['material_type'].append(article['type_of_material'])\n",
    "            else:\n",
    "                data['material_type'].append(None)\n",
    "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "            data['keywords'].append(keywords)\n",
    "    return pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dates):\n",
    "    '''Sends and parses request/response to/from NYT Archive API for given dates.'''\n",
    "    total = 0\n",
    "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
    "    if not os.path.exists('headlines'):\n",
    "        os.mkdir('headlines')\n",
    "    for date in dates:\n",
    "        response = send_request(date)\n",
    "        df = parse_response(response)\n",
    "        total += len(df)\n",
    "        df.to_csv('headlines/' + date[0] + '-' + date[1] + '.csv', index=False)\n",
    "        print('Saving headlines/' + date[0] + '-' + date[1] + '.csv...')\n",
    "    print('Number of articles collected: ' + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"http://api.nytimes.com/svc/search/v2/articlesearch.json?q={search_query}&begin_date={begin_date}&end_date={end_date}&api-key={config.api_key}\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a1471f50df7cb319e29395b59b1e7aab4c7d05189145630a960a14c126a82d6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
